"use strict";(self.webpackChunkq10viking_github_io=self.webpackChunkq10viking_github_io||[]).push([[49650],{29896:(i,e,l)=>{l.r(e),l.d(e,{data:()=>d});const d={key:"v-385122a6",path:"/Redis/56%20Redis%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98.html",title:"",lang:"zh-CN",frontmatter:{sidebarDepth:3,sidebar:"auto",prev:{text:"Back To 目录",link:"/Redis/"},"typora-root-url":"..\\.vuepress\\public"},excerpt:"",headers:[{level:2,title:"Redis相比memcached有哪些优势",slug:"redis相比memcached有哪些优势",children:[]},{level:2,title:"Redis真的是单线程吗",slug:"redis真的是单线程吗",children:[]},{level:2,title:"Redis6为何引入多线程？",slug:"redis6为何引入多线程",children:[]},{level:2,title:"Redis是如何解决Hash冲突的？",slug:"redis是如何解决hash冲突的",children:[]},{level:2,title:"MySQL里有2000w数据Redis中只存20w的数据，如何保证 redis 中的数据都是热点数据？",slug:"mysql里有2000w数据redis中只存20w的数据-如何保证-redis-中的数据都是热点数据",children:[]},{level:2,title:"高并发场景下我们如何保证幂等性",slug:"高并发场景下我们如何保证幂等性",children:[]},{level:2,title:"Redis如何保证与数据库的双写一致性",slug:"redis如何保证与数据库的双写一致性",children:[]},{level:2,title:"谈谈缓存穿透、击穿、雪崩的区别，又如何去解决",slug:"谈谈缓存穿透、击穿、雪崩的区别-又如何去解决",children:[{level:3,title:"缓存穿透",slug:"缓存穿透",children:[]},{level:3,title:"缓存击穿",slug:"缓存击穿",children:[]},{level:3,title:"缓存雪崩",slug:"缓存雪崩",children:[]}]},{level:2,title:"灰度发布",slug:"灰度发布",children:[]},{level:2,title:"雪花算法",slug:"雪花算法",children:[]},{level:2,title:"雪花ID算法的前世今生",slug:"雪花id算法的前世今生",children:[]},{level:2,title:"Redis的事务",slug:"redis的事务",children:[]}],filePathRelative:"Redis/56 Redis相关面试题.md"}},802:(i,e,l)=>{l.r(e),l.d(e,{default:()=>r});const d=(0,l(20641).Fv)('<h2 id="redis相比memcached有哪些优势" tabindex="-1"><a class="header-anchor" href="#redis相比memcached有哪些优势" aria-hidden="true">#</a> Redis相比memcached有哪些优势</h2><p>这是一道非常常见的面试题，也是大家在工作中很容易忽略掉的点，大部分场景下redis确实更适合用于我们项目，但是我们可能答不上来它们都作为键值对数据库其中的区别是什么。</p><ol><li><p>从<strong>数据结构</strong>侧来说，memcached仅支持value为string类型，而我们redis支持的类型是相当丰富的，有string、hash、list、set、sort set等等，所以在功能上redis是比我们memcached支持的更好的。还有就是memcached的单value值容量只有1M，而我们的redis则最大支持至512M。</p></li><li><p>从<strong>数据持久化</strong>来说，memcached只做缓存，没有可靠性的需求，所以是不支持的，只要断电或者服务关闭之后那么就会丢失内存中的数据，而redis更倾向于内存数据库，如果我们有持久化需求的话可以优先考虑redis。</p></li><li><p>同时我们的<strong>redis还支持lua脚本</strong>，脚本提交是原子执行的，我们在面对复杂业务场景中，需要保证按照我们所需的顺序一步步执行就可以通过我们的lua脚本来解决。</p></li></ol><h2 id="redis真的是单线程吗" tabindex="-1"><a class="header-anchor" href="#redis真的是单线程吗" aria-hidden="true">#</a> Redis真的是单线程吗</h2><p>所谓的redis单线程其实指的是在网络IO和键值对读写时是通过一个线程完成的。而其他的一些模块比如说持久化存储、集群支撑模块这些都是多线程的。</p><p>那为什么网络操作模块和数据存储模块不用多线程呢？</p><p>其实非常简单，首先网络IO模块的性能瓶颈就不在CPU上，而是要提升我们的IO利用率，虽然使用多线程能带来一些提升，但是多线程也是存在一定的弊端的，首先是多线程模型下的共享资源和并发控制非常复杂，线程的上线文切换也会带来一定的性能损耗，所以Redis在这块采用的是IO多路复用。</p><p>另一方面，Redis的绝大部分操作都是在内存中完成的，内存操作本来就比硬盘读写快了百倍以上，并且在数据结构上也进行了大量的优化，比如hash表和跳表。而使用单线程还能避免多线程下的锁竞争，省去了线程的时间和性能开销也不会存在锁竞争的问题。</p><h2 id="redis6为何引入多线程" tabindex="-1"><a class="header-anchor" href="#redis6为何引入多线程" aria-hidden="true">#</a> Redis6为何引入多线程？</h2><p>redis6中引入的多线程是正对于网络IO模块进行了多线程改造，因为多路复用的IO模型本质上来说还是同步阻塞型IO模型，在调用epoll的过程是阻塞的，并发量极高的场景就成为了性能瓶颈，那么在碰到这类问题上，就可以通过多线程来解决。它通过多线程解决了网络IO等待造成的影响，还可以充分利用CPU的多核优势。对于我们读写模块依旧还是采用的单线程模型，避免了多线程环境下并发访问带来的很多问题。在简单的get/set命令性能上多线程IO模型提升了有接近一倍。</p><h2 id="redis是如何解决hash冲突的" tabindex="-1"><a class="header-anchor" href="#redis是如何解决hash冲突的" aria-hidden="true">#</a> Redis是如何解决Hash冲突的？</h2><p>redis是通过我们的链式hash来解决我们的hash冲突问题: <strong>链地址法的基本思想</strong>是：<strong>将哈希表的每个桶都设为一个链表，当哈希冲突发生时，新的键值对会添加到链表的末尾</strong>。这样，每个桶就可以存储多个键值对。当需要查找键值对时，只需要在相应的链表中查找即可。</p><p>哈希算法产生的哈希值的长度是固定并且是有限的，比如说我们通过MD5算法生成32位的散列值，那么它能生成出来的长度则是有限的，我们的数据如果大于32位是不是就可能存在不同数据生成同一个散列值，那么redis通过链式hash，以不扩容的前提下把有相同值的数据链接起来，但是如果链表变得很长就会导致性能下降，那么redis就采用了rehash的机制来解决，类似于hashmap里面的扩容机制，但是redis中的rehash并不是一次把hash表中的数据映射到另外一张表，而是通过了一种渐进式的方式来处理，将rehash分散到多次请求过程中，避免阻塞耗时。</p><h2 id="mysql里有2000w数据redis中只存20w的数据-如何保证-redis-中的数据都是热点数据" tabindex="-1"><a class="header-anchor" href="#mysql里有2000w数据redis中只存20w的数据-如何保证-redis-中的数据都是热点数据" aria-hidden="true">#</a> MySQL里有2000w数据Redis中只存20w的数据，如何保证 redis 中的数据都是热点数据？</h2><p>首先我们可以看到Redis的空间时间上比我们MySQL少的多，那么Redis如何能够筛选出热点数据，这道题主要考察的是Redis的数据淘汰策略。</p><ol><li>oeviction 选择这种策略则代表不进行数据淘汰，同时它也是redis中默认的淘汰策略，当缓存写满时redis就不再提供写服务了，写请求则直接返回失败。</li><li>random 随机策略这块则是分为两种，一种是volatile，这种是设置了过期时间得数据集，而另外一种是allkeys，这种是包含了所有的数据，当我们缓存满了的时候，选用这种策略就会在我们的数据集中进行随机删除。</li><li>volatile-ttl 这种策略是针对设置了过期时间的数据，并且按照过期时间的先后顺序进行删除，越早过期的越先被删除</li><li>lru 这里的lru策略和我们上面random策略一样也是提供了两种数据集进行处理，LRU算法全程为（最近最少使用）简单一句话来概括就是“如果数据最近被访问过，那么将来被访问的几率也就越高”。这种算法其实已经比较符合我们的实际业务需求了，但是还是存在一些缺陷。</li><li>lfu 最后一种策略就是我们的LFU算法，它是在我么LRU算法基础上增加了请求数统计，这样能够更加精准的代表我们的热点数据。</li></ol><p>我们再回看我们的这个问题，我们能很清楚的知道，我们<strong>需要的策略是LFU算法。选择volatile还是allkeys就要根据具体的业务需求了</strong>。</p><h2 id="高并发场景下我们如何保证幂等性" tabindex="-1"><a class="header-anchor" href="#高并发场景下我们如何保证幂等性" aria-hidden="true">#</a> 高并发场景下我们如何保证幂等性</h2><p>首先普及下幂等的概念“在计算机中编程中，一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。”</p><p>那么在我们的实际业务场景中幂等是一个非常高频的场景，比如：</p><ul><li>电商场景中用户因网络问题多次点击导致重复下单问题</li><li>MQ消息队列的重复消费</li><li>RPC中的超时重试机制</li><li>等等</li></ul><p>那么我们有那些方案可以解决我们的幂等性问题呢？</p><ul><li><p>数据库唯一主键实现幂等性</p></li><li><ul><li>其实现方式是使用分布式ID充当主键，不使用MySQL中的自增主键</li></ul></li><li><p>乐观锁实现幂等性</p></li><li><ul><li>在表中增加版本号标识，只有版本号标识一直才更新成功</li></ul></li><li><p>分布式锁</p></li><li><ul><li>简单来说就是分布式的排他锁，但是我们可以控制锁的粒度以提高程序的执行性能</li></ul></li><li><p>获取token</p></li></ul><ol><li><ol><li>服务端提供获取 Token 的接口，请求前客户端调用接口获取 Token</li><li>然后将该串存入 Redis 数据库中，以该 Token 作为 Redis 的键（注意设置过期时间）。</li><li>将 Token 返回到客户端，在执行业务请求带上该 Token</li><li>服务端接收到请求后根据 Token 到 Redis 中查找该 key 是否存在（注意原子性），</li><li>如果存在就将该 key 删除，然后正常执行业务逻辑。如果不存在就抛异常，返回重复提交的错误信息。</li></ol></li></ol><h2 id="redis如何保证与数据库的双写一致性" tabindex="-1"><a class="header-anchor" href="#redis如何保证与数据库的双写一致性" aria-hidden="true">#</a> Redis如何保证与数据库的双写一致性</h2><p>解决双写一致性方案：</p><ul><li><p>延迟双删</p></li><li><ul><li>延迟双删策略是分布式系统中数据库存储和缓存数据保持一致性的常用策略，但它不是强一致。</li><li>实现思路：也是非常简单的，先删除缓存然后更新DB在最后延迟 N 秒去再去执行一次缓存删除</li><li>弊端：小概率会出现不一致情况、耦合程度高</li></ul></li><li><p>通过MQ进行重试删除</p></li><li><ul><li>更新完DB之后进行删除，如果删除失败则向MQ发送一条消息，然后消费者不断进行删除尝试。</li></ul></li><li><p>binlog异步删除</p></li><li><ul><li>实现思路：低耦合的解决方案是使用canal。canal伪装成mysql的从机，监听主机mysql的二进制文件，当数据发生变化时发送给MQ。最终消费进行删除</li></ul></li></ul><h2 id="谈谈缓存穿透、击穿、雪崩的区别-又如何去解决" tabindex="-1"><a class="header-anchor" href="#谈谈缓存穿透、击穿、雪崩的区别-又如何去解决" aria-hidden="true">#</a> 谈谈缓存穿透、击穿、雪崩的区别，又如何去解决</h2><h3 id="缓存穿透" tabindex="-1"><a class="header-anchor" href="#缓存穿透" aria-hidden="true">#</a> 缓存穿透</h3><p>缓存穿透代表的意思是在我们的缓存中没有找到缓存信息，那么我们在高并发场景下就会面临所有的请求都会直接打到DB，缓存则失去了它原本的意义，并且极有可能导致数据库压力过大而造成服务不可用。</p><ul><li>缓存空结果信息</li><li>布隆过滤器（不存在的一定不存在，存在的可能不存在，通过bitmap实现，想深入布隆过滤器可以专门去看看这部分专题内容）</li><li>过滤常见非法参数，拦截大部分无效请求（）</li></ul><h3 id="缓存击穿" tabindex="-1"><a class="header-anchor" href="#缓存击穿" aria-hidden="true">#</a> 缓存击穿</h3><p>缓存击穿代表的意思是我们数据库中存在数据,但是缓存中不存在数据.这种场景一般是在缓存失效时发生的. 在高并发的场景下极有可能瞬间打垮数据库.</p><ul><li>我们可以考虑面对请求量大的热点接口直接将缓存设置永不过期.</li><li>当然我们也可能碰到一些特殊场景不能设置永久缓存,那么我们可以在db为空时设置互斥锁,当查询完db更新至缓存时再释放锁</li></ul><h3 id="缓存雪崩" tabindex="-1"><a class="header-anchor" href="#缓存雪崩" aria-hidden="true">#</a> 缓存雪崩</h3><p>缓存雪崩代表是意思是我们在某一个时间段,碰到大量热点缓存数据过期导致大量请求直接打垮数据库</p><ul><li>我们可以考虑面对请求量大的热点接口直接将缓存设置永不过期.</li><li>缓存过期时间可以设置一个随机的波动值,防止大量数据在同一时间过期</li></ul><h2 id="灰度发布" tabindex="-1"><a class="header-anchor" href="#灰度发布" aria-hidden="true">#</a> 灰度发布</h2><p>灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。AB test就是一种灰度发布方式，让一部分用户继续用A，一部分用户开始用B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度，而我们平常所说的金丝雀部署也就是灰度发布的一种方式。</p><h2 id="雪花算法" tabindex="-1"><a class="header-anchor" href="#雪花算法" aria-hidden="true">#</a> 雪花算法</h2><h2 id="雪花id算法的前世今生" tabindex="-1"><a class="header-anchor" href="#雪花id算法的前世今生" aria-hidden="true">#</a> 雪花ID算法的前世今生</h2><p>snowflake是Twitter开源的分布式ID生成算法，结果是64bit的Long类型的ID，有着全局唯一和有序递增的特点。</p><ul><li>最高位是符号位，因为生成的 ID 总是正数，始终为0，不可用。</li><li>41位的时间序列，精确到毫秒级，41位的长度可以使用69年。时间位还有一个很重要的作用是可以根据时间进行排序。</li><li>10位的机器标识，10位的长度最多支持部署1024个节点。</li><li>12位的计数序列号，序列号即一系列的自增ID，可以支持同一节点同一毫秒生成多个ID序号，12位的计数序列号支持每个节点每毫秒产生4096个ID序号。</li></ul><p>缺点也是有的，就是强依赖机器时钟，如果机器上时钟回拨，有可能会导致主键重复的问题。</p><h2 id="redis的事务" tabindex="-1"><a class="header-anchor" href="#redis的事务" aria-hidden="true">#</a> Redis的事务</h2><p>不保证原子性</p><ul><li>事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚</li></ul>',47),a={},r=(0,l(66262).A)(a,[["render",function(i,e){return d}]])},66262:(i,e)=>{e.A=(i,e)=>{const l=i.__vccOpts||i;for(const[i,d]of e)l[i]=d;return l}}}]);