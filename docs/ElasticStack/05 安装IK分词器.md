---
sidebarDepth: 3
sidebar: auto
prev:
  text: Back To 目录
  link: /ElasticStack/
typora-root-url: ..\.vuepress\public
---

##  IK分词器

::: tip

[elasticsearch-analysis-ik-7.6.1 download](https://github.com/medcl/elasticsearch-analysis-ik/releases/tag/v7.6.1)

:::

```sh
# 1）创建目录
mkdir -p /usr/es/elasticsearch-7.6.1/plugins/ik
# 2） 将下载的ik分词器上传并解压到该目录
cd /usr/local/es/elasticsearch-7.6.1/plugins/ik
unzip  elasticsearch-analysis-ik-7.6.1.zip 
# 3）需要重启elasticsearch
```

##  测试分词效果

```json
// elasticsearch默认的分词器会分为一个个中文
POST _analyze
{
	"analyzer":"standard",
	"text":"我爱你中国"
}
//	ik_smart:会做最粗粒度的拆分
POST _analyze
{
    "analyzer":"ik_smart",
    "text":"我爱你中国"
}

// ik_max_word:会将文本做最细粒度的拆分 也就是会拆分为更多的词
POST _analyze
{
	"analyzer":"ik_max_word",
	"text":"我爱你中国"
}
```

![image-20220812185155730](/images/elasticsearch/image-20220812185155730.png)

![image-20220812185239889](/images/elasticsearch/image-20220812185239889.png)



### ik_smart（粗粒度）

ik_smart会将“清华大学”整个分为一个词。

```json
POST _analyze
{
"analyzer":"ik_smart",
"text":"清华大学"
}

```

![image-20220812185354012](/images/elasticsearch/image-20220812185354012.png)

### ik_max_world(细粒度)

ik_max_word会将“清华大学”分为“清华大学”，“清华”和“大学”

```json
POST _analyze
{
    "analyzer":"ik_max_word",
    "text":"清华大学"
}

```

![image-20220812185610197](/images/elasticsearch/image-20220812185610197.png)

