---
typora-root-url: images
---

Socket与http请求

## 长连接

::: tip

connect:keep-alive分析，多个http请求可以公用一个socket进行收发数据

和close

:::

## 请求行的处理

**http协议的解析**， "主要是请求行和请求头"

通过01010的字节数据传输到机器上。tomcat中从操作系统内核的Socket缓冲区中，读数据到字节缓冲区中。tomcat从这个缓冲区中获取字节数据，根据http协议解析出来对应的字节数据段。封装到具体的类中。在解析缓冲区的字节数据时会设置相应的下标pos,end,lastvalid来进行表示处理到的位置。

当处理解析完请求行和请求头之后，就进入到servlet的业务方法了，暂时不再进行请求体的解析。

BIO中：从底层的socket缓冲区中，有可能只取到部分的数据，那么在解析的时候，如果没有完全解析出请求体和请求行，那么就会继续从socket缓冲区中读取数据，这个过程会发生阻塞。

NIO中： 从底层socket读取，如果没有数据，因为nio 设置的socketchannel是非阻塞的，那么就会返回读取的数据量是0.那么整个处理的就结束了，对应的处理线程socketProcessor也就结束了。直到下一次读的就绪事件好了之后，在从线程池中获取一个socketProcessor的线程去进行读取。那么重新启动线程之后，是如何衔接到之前处理数据的地方呢？原因是new SocketProcessor（**也是一个runnable,只是一个任务，任务结束就结束了，但是线程依旧回归到线程池中）**，**封装了NioSocketChannel(里面有socketchannel) 当在处理http协议的时候，会根据一个map< socket ,Http11Processor > 取出对应Http11Processor进行对应的处理**

 ![image-20220507232142617](/image-20220507232142617.png)



byte 可以对应起来一个character，这样就转换成字符，根据http协议，将http解析出来，设置到具体类的属性当中。

只有一个缓冲区



## 请求体的处理

方式1： **content-length**:   可以ByteChunk长度标记**请求体的结束** tomcat对应的处理IdentityInputFilter

方式二：**分块传输** ChunkedInputFilter 每次read就只读取到一块数据

这两个过滤器根据请求头是什么上面两种方式来分别设置

```
Transfer-Encoding: chunked


数据
2\r\n   header   这是一个分块，表示要传输的数据长度是2   
aa\r\n

1\r\n      这也是一个分块，表示要传输的数据长度是1
a\r\n

0\r\n      标记请求体的结束
\r\n
```

**在长连接的过程请求的处理是串行的: ** 处理了一个请求，然后再处理另外一个请求。请求处理完成，**缓存的字节数组的复用**。

区分好：长连接与请求的关系。长连接过程中会发送多个请求。短链接过程中只会发送一个请求。

```java
// 这个InputStream并不是Socket.getInputStream
// ServletInputStream它自己维护了一个缓存，由它从socket中读取数据先放入到ServletInputStream中维护的缓冲区中
ServletInputStream in = request.getInputStream()
```

-----------

## 响应体的处理

先写入缓存ByteChunk中有数组byte[] buf,当缓冲区的数据

```java
// respones 相应头content-length,和chunk
CoyoteOutputStream outputStream = resp.getOutputStream();
outputstream.write("Q10Viking".getBytes());
// flush() // 会发送响应头 chunk
```

buf缓冲区-->ByteOutBuff.realWrite到第二个socketBuf缓冲区--->

chunk 使用ChunkedOuputFilter,将数据真正的写入到socket中

![image-20220507012552584](/image-20220507012552584.png)

**第二级别缓存socketbuffer什么时候触发开始往socket中写？**

主要是tomcat在发送数据时会要先处理响应头

**flushBuffer的时候**，只不过是tomcat自己主动调用，还是

两种方式：

第一种：

flush(方法时其本身就会触发往socket中写入数据)，将构建响应头到第二级别缓存，将第一级的数据缓存放到第二级缓存(调用ChunkOutPutFilter构造chunk形式的响应体到第二级别缓冲区)，然后发送到socket



第二种：



（**注意这种情况是第一级别的缓存始终没有满过，也就是说从来没有发送过响应头，此时是content-length**）serlvet中没有手动触发flush,serlvet中业务代码处理结束后，回到tomcat中的处理请求的逻辑，继续往下走,再处理相应的时候，endRequest, 将一级别缓冲区拷贝到二级别缓冲区，然后再触发第二级缓冲区的flushBuff方法发送到socket.



另外一种是在servlet业务代码中不断的调用write方法，就会先往第一级别的缓冲区写，如果满了之后，放入到第二级别缓冲区，然后触发socket的写。（也就是说放入到第二级别缓冲区后，就会触发socket的写），此时就是chunk方式的写。



----------

**NIO处理请求体的情况**

1. 在业务层是去取数据，如果tomcat中缓存中有数据了，直接去取
2. 如果tomcat中缓存中还没有数据，那么就会阻塞，因为nio是通过事件通知的形式触发的，当前没没有READ的事件触发，nio不会从内核缓冲区中读取数据到tomcat中的缓冲区。此时业务层的调用就应该阻塞，直到nio获得了READ的通知，将数据从内核放入到tomcat缓冲区中。

### NIO处理连接的情况Reactor模型

每次连接建立生成一个socketChannel，把它绑定到一个线程中去,这个socketChannel会在该处理线程的Selector.open()中(**Selector.open()每次获取都是同一个对象吗？**)，注册相应的就绪事件。

每次IO事件发生就交给一个线程去处理？这不会出现数据割裂的情况吗？比如说一个请求过来，触发IO事件的READ,可能内核底层先收到了一部分数据，后半部分数据由于网络抖动才发过来。不就开了两个线程吗？解决方式：用一个缓存记录了socket与HttpNioProcessor的关系，所以数据解析都会到同一个地方。那么有序性是如何保证的呢?
