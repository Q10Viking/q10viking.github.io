---
sidebarDepth: 3
sidebar: auto
prev:
  text: Back To 目录
  link: /kafka/
typora-root-url: ..\.vuepress\public
---



## 消费者位移主题

> 新版本 Consumer 的位移管理机制就是将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 __consumer_offsets 中。可以这么说，__consumer_offsets 的主要作用是保存 Kafka 消费者的位移信息。它要求这个提交过程不仅要实现高持久性，还要支持高频的写操作。

![image-20230422135104093](/images/kafka/image-20230422135104093.png)

```sh
q10viking@LAPTOP-PJLAUUSP:~/software/kafka_2.12-2.5.0/kafka-logs$ ls
__consumer_offsets-0   __consumer_offsets-34
__consumer_offsets-1   __consumer_offsets-35
__consumer_offsets-10  __consumer_offsets-36
__consumer_offsets-11  __consumer_offsets-37
__consumer_offsets-12  __consumer_offsets-38
__consumer_offsets-13  __consumer_offsets-39
__consumer_offsets-14  __consumer_offsets-4
__consumer_offsets-15  __consumer_offsets-40
__consumer_offsets-16  __consumer_offsets-41
__consumer_offsets-17  __consumer_offsets-42
__consumer_offsets-18  __consumer_offsets-43
__consumer_offsets-19  __consumer_offsets-44
__consumer_offsets-2   __consumer_offsets-45
__consumer_offsets-20  __consumer_offsets-46
__consumer_offsets-21  __consumer_offsets-47
__consumer_offsets-22  __consumer_offsets-48
__consumer_offsets-23  __consumer_offsets-49
__consumer_offsets-24  __consumer_offsets-5
__consumer_offsets-25  __consumer_offsets-6
__consumer_offsets-26  __consumer_offsets-7
__consumer_offsets-27  __consumer_offsets-8
__consumer_offsets-28  __consumer_offsets-9
__consumer_offsets-29  cleaner-offset-checkpoint
__consumer_offsets-3   log-start-offset-checkpoint
__consumer_offsets-30  meta.properties
__consumer_offsets-31  recovery-point-offset-checkpoint
__consumer_offsets-32  replication-offset-checkpoint
__consumer_offsets-33  test-0
```

### 消息

`__consumer_offsets` 的每条消息格式大致如图所示

![img](/images/kafka/7000.png)

该主题用于消费者提交消费位移。



## 分析



> 创建一个主题test,分区6

```sh
 bin/kafka-topics.sh --create --zookeeper 172.29.96.105:2181 --replication-factor 1 --partitions 6 --topic test
```



> 创建一个消费者属于order-group消费组，消费test主题

```sh
bin/kafka-console-consumer.sh --bootstrap-server 172.29.96.105:9092 --topic test 
# 指定消费者分组
bin/kafka-console-consumer.sh --bootstrap-server  172.29.96.105:9092 --group order-group --topic test
```

会创建一个消费者进行消费

```
[Consumer clientId=consumer-order-group-1, groupId=order-group] 
```



> 生产消费

```sh
bin/kafka-console-producer.sh --broker-list 172.29.96.105:9092 --topic test
```

### 测试

> 测试一个消费组order-group中有两个消费者，生产6条消息
> 可以看到消息只会被消费一次，左边的消费到了3条，右边的消费到了3条

![image-20230422151458500](/images/kafka/image-20230422151458500.png)





### 查看消费位移

```sh
bin/kafka-consumer-groups.sh --bootstrap-server 172.29.96.105:9092 --describe --group order-group
```

可以看到主题下的6个分区都被消费组的2个消费者给接管了

![image-20230422152153042](/images/kafka/image-20230422152153042.png)

```sh
GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                                 HOST            CLIENT-ID
order-group     test            0          2               2               0               consumer-order-group-1-0ff47fdc-30d1-421d-9541-91681c21c881 /172.29.96.105  consumer-order-group-1
order-group     test            1          0               0               0               consumer-order-group-1-0ff47fdc-30d1-421d-9541-91681c21c881 /172.29.96.105  consumer-order-group-1
order-group     test            2          1               1               0               consumer-order-group-1-0ff47fdc-30d1-421d-9541-91681c21c881 /172.29.96.105  consumer-order-group-1
order-group     test            3          0               0               0               consumer-order-group-1-b32793ec-1bdd-4c47-857a-e49966548bc0 /172.29.96.105  consumer-order-group-1
order-group     test            4          1               1               0               consumer-order-group-1-b32793ec-1bdd-4c47-857a-e49966548bc0 /172.29.96.105  consumer-order-group-1
order-group     test            5          2               2               0               consumer-order-group-1-b32793ec-1bdd-4c47-857a-e49966548bc0 /172.29.96.105  consumer-order-group-1
q10viking@LAPTOP-PJLAUUSP:~/software/kafka_2.12-2.5.0$
```



> 现在再启动一个消费者,6个分区做了调整分配给3个消费者，并且新的消费者继承了之前的消费位点

![image-20230422153005839](/images/kafka/image-20230422153005839.png)



```sh
CURRENT-OFFSET: 当前消费组消费到的偏移量
LOG-END-OFFSET: 日志最后的偏移量
CURRENT-OFFSET = LOG-END-OFFSET 说明当前消费组已经全部消费了;
```



> 当下线一个消费者的时候，这个消费本来处理的分区又会重分配给其他消费，直到将组内的所有的消费都下线后，可以看到，组内没有消费者接管分区

![image-20230422153720399](/images/kafka/image-20230422153720399.png)



> 现在生产者再发送三条条消息，可以看到其中有三个分区的消费位移落后于日志的偏移量

![image-20230422154007259](/images/kafka/image-20230422154007259.png)



> 此时再重新上线一个消费者

![image-20230422154406330](/images/kafka/image-20230422154406330.png)

积压的消息被这个消费者给接收了

![image-20230422154530529](/images/kafka/image-20230422154530529.png)



> 此时上线一个从头消费的消费者会怎么样呢？

```sh
bin/kafka-console-consumer.sh --bootstrap-server  172.29.96.105:9092 --group order-group --from-beginning --topic test
```



此时如下图所示，有一个消费者已经在消费类，尽管又上线了一个消费者是从头开始消费者，但是由于组内存在其他消费者，已经消费完了消息，所以这个新上线的消费者并没有消费到消息。

![image-20230422155343023](/images/kafka/image-20230422155343023.png)

但是它仍然接收部分的分区

![image-20230422155708454](/images/kafka/image-20230422155708454.png)



> 现在下线全部的消费，然后只上线一个从头消费者，会不会打印之前的消息呢？
>
> 可以看到，还是没有从头消费到消息。因为order-group组的消费位移已经等于日志的位移。所以没有消息接收

![image-20230422160133493](/images/kafka/image-20230422160133493.png)



> 新上线一个消费组，member-group,用一个消费从头消费

```sh
bin/kafka-console-consumer.sh --bootstrap-server  172.29.96.105:9092 --group member-group --from-beginning --topic test
```

可以看到消费到了历史消息

![image-20230422161001100](/images/kafka/image-20230422161001100.png)

并且`member-group`消费位移已经更新到了与日志位移一致的位置。

![image-20230422160915950](/images/kafka/image-20230422160915950.png)

> 新上线一个消费组，goods-group,用一个消费者从kafka当前消费存储的位移开始消费

```sh
bin/kafka-console-consumer.sh --bootstrap-server  172.29.96.105:9092 --group goods-group --topic test

bin/kafka-console-consumer.sh --bootstrap-server  172.29.96.105:9092 --group hzz-group --consumer-property group.id=hzz --topic test 
```

可以看到goods-group没有消费到消息。

![image-20230422161423638](/images/kafka/image-20230422161423638.png)



`goods-group`消费组的消费位移已经更新到了与日志位移一致的位置。

![image-20230422161258503](/images/kafka/image-20230422161258503.png)



> 现在我们有三个消费组订阅了test主题，那么我们现在向这个主题发送一条消息，看看会怎么样。



如下图所示：每个消费组都收到了这条消息。其中order-group有两个消费者，只有一个消费接收到了消息。原因是：goods-group和member-group消费组都各自只有一个消费者，这个消费者接管了该组的topic的所有分区。而order-group的两个消费者，topic的6个分区被分成了3份+3份，这个两个消费者分别接收这3份，数据只插入其中一个分区，那么这个哪个消费者接管这块分区，就谁收到消息。



![image-20230422162423224](/images/kafka/image-20230422162423224.png)

分区接收情况

![image-20230422163241046](/images/kafka/image-20230422163241046.png)



### 小结

`--from-beginning`是对新的消费组来说的。





## 如何确认 consume_group 在哪个__consumer_offsets-? 中

```java
// Math.abs(groupID.hashCode()) % numPartitions
String groupid = "goods-group";
// 38
int r = Math.abs(groupid.hashCode())%50;
```



## 查找__consumer_offsets 分区数中的消费组偏移量offset❤️

> 第一种方式： 确定消费组上传的消息在`__consumer_offsets`中的分区，然后我们进行消费查询

先通过 `consume_group` 确定分区数; 例如 `"goods-group".hashCode()%50=26`; 那我们就知道 `goods-group`消费组的偏移量信息存放在 `__consumer_offsets-38`中; 通过命令

> 消费主题`__consumer_offsets-38`下的分区38的消息

```sh
bin/kafka-console-consumer.sh --bootstrap-server 172.29.96.105:9092 --topic __consumer_offsets --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" --partition 38
```

结果：这里只是截取了`Sat Apr 22 18:59:20 GMT+08:00 2023`时间点，消费端上传的消息，消费端每隔5秒上传一次消费位点。

```sh
[goods-group,test,0]::OffsetAndMetadata(offset=4, leaderEpoch=Optional[0], metadata=, commitTimestamp=1682161160164, expireTimestamp=None)
[goods-group,test,5]::OffsetAndMetadata(offset=3, leaderEpoch=Optional[0], metadata=, commitTimestamp=1682161160164, expireTimestamp=None)
[goods-group,test,1]::OffsetAndMetadata(offset=1, leaderEpoch=Optional[0], metadata=, commitTimestamp=1682161160164, expireTimestamp=None)
[goods-group,test,4]::OffsetAndMetadata(offset=1, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1682161160164, expireTimestamp=None)
[goods-group,test,3]::OffsetAndMetadata(offset=1, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1682161160164, expireTimestamp=None)
[goods-group,test,2]::OffsetAndMetadata(offset=2, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1682161160164, expireTimestamp=None)
```

通过看时间戳：发现消费端每次5s上传一次消费位点

```sh
//Sat Apr 22 18:59:20 GMT+08:00 2023
//Sat Apr 22 18:59:25 GMT+08:00 2023
//Sat Apr 22 18:59:30 GMT+08:00 2023
//Sat Apr 22 18:59:35 GMT+08:00 2023
//Sat Apr 22 18:59:40 GMT+08:00 2023
```



> 第二种方式：就是上面例子中用到的

```sh
bin/kafka-consumer-groups.sh --bootstrap-server 172.29.96.105:9092 --describe --group goods-group
```

```
GROUP           TOPIC      PARTITION  CURRENT-OFFSET  LOG-END-OFFSET      LAG   CONSUMER-ID    HOST            CLIENT-ID
goods-group     test            0          4               4               0
goods-group     test            5          3               3               0
goods-group     test            1          1               1               0
goods-group     test            4          1               1               0
goods-group     test            3          1               1               0
goods-group     test            2          2               2               0
```



## 查询topic的分布情况

```sh
bin/kafka-topics.sh --describe --zookeeper 172.29.96.105:2181 --topic test
Topic: test     PartitionCount: 6       ReplicationFactor: 1    Configs:
        Topic: test     Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: test     Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: test     Partition: 2    Leader: 0       Replicas: 0     Isr: 0
        Topic: test     Partition: 3    Leader: 0       Replicas: 0     Isr: 0
        Topic: test     Partition: 4    Leader: 0       Replicas: 0     Isr: 0
        Topic: test     Partition: 5    Leader: 0       Replicas: 0     Isr: 0
```





## 常用命令❤️

```sh
 # 创建一个主题
 bin/kafka-topics.sh --create --zookeeper 172.29.96.105:2181 --replication-factor 1 --partitions 6 --topic test
 #查看指定主题的分布情况
 bin/kafka-topics.sh --describe --zookeeper 172.29.96.105:2181 --topic test
 # 删除主题
 bin/kafka-topics.sh --delete --topic test --zookeeper 172.29.96.105:2181
 # 主题列表
 bin/kafka-topics.sh --list --zookeeper 172.29.96.105:2181
 
 #################################################################################################################
 
 # 创建一个消费者组消费主题
 bin/kafka-console-consumer.sh --bootstrap-server  172.29.96.105:9092 --group order-group --topic test
 # 消费指定主题的某个分区
 bin/kafka-console-consumer.sh --bootstrap-server 172.29.96.105:9092 --topic __consumer_offsets --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" --partition 38
 # 查看消费位移
 bin/kafka-consumer-groups.sh --bootstrap-server 172.29.96.105:9092 --describe --group order-group
 # 消费组列表
 bin/kafka-consumer-groups.sh --bootstrap-server 172.29.96.105:9092 --list
 
 #################################################################################################################
 # 向指定主题生产消息
 bin/kafka-console-producer.sh --broker-list 172.29.96.105:9092 --topic test
```





## 参考

[【kafka原理】 消费者偏移量__consumer_offsets_相关解析 - 腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1846774)

[kafka 查看消费者组_kafka查看消费者组命令_鸭梨山大哎的博客-CSDN博客](https://blog.csdn.net/u010711495/article/details/112133491)

