---
sidebarDepth: 3
sidebar: auto
prev:
  text: Back To 目录
  link: /kafka/
typora-root-url: ..\.vuepress\public
---





## 基本概念

- 主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。
- 分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区

- 消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。
- 消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。
- 消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。

![image-20230421225112269](/images/kafka/image-20230421225112269.png)



### **主题Topic和消息日志Log**

**可以理解Topic是一个类别的名称，同类消息发送到同一个Topic下面。对于每一个Topic，下面可以有多个分区(Partition)日志文件**

![https://note.youdao.com/yws/public/resource/b0357bdb4821ed2e35ecdbdacd65aa06/xmlnote/88B28CF6D35942F2B393E5A32632ABEC/122862](/images/kafka/122862.png)



- Partition是一个**有序的message序列**，这些message按顺序添加到一个叫做**commit log的文件**中。每个partition中的消息都有一个唯一的编号，称之为offset，用来唯一标示某个分区中的message
- **每个partition，都对应一个commit log文件**。一个partition中的message的offset都是唯一的，但是不同的partition中的message的offset可能是相同的。

> test主题，分区test-0下的log文件

```sh
q10viking@LAPTOP-PJLAUUSP:~/software/kafka_2.12-2.5.0/kafka-logs/test-0$ ls
00000000000000000000.index      00000000000000000007.snapshot
00000000000000000000.log        leader-epoch-checkpoint
```

- kafka一般不会删除消息，不管这些消息有没有被消费。只会根据配置的日志保留时间(log.retention.hours)确认消息多久被删除，默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系，因此保存大量的数据消息日志信息不会有什么影响

**每个consumer是基于自己在commit log中的消费进度(offset)来进行工作的**。在kafka中，**消费offset由consumer自己来维护**；一般情况下我们按照顺序逐条消费commit log中的消息，当然我可以通过指定offset来重复消费某些消息，或者跳过某些消息。

这意味kafka中的consumer对集群的影响是非常小的，添加一个或者减少一个consumer，对于集群或者其他consumer来说，都是没有影响的，因为每个consumer维护各自的消费offset。



### 消费者位移主题

> 新版本 Consumer 的位移管理机制就是将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 __consumer_offsets 中。可以这么说，__consumer_offsets 的主要作用是保存 Kafka 消费者的位移信息。它要求这个提交过程不仅要实现高持久性，还要支持高频的写操作。

![image-20230422135104093](/images/kafka/image-20230422135104093.png)

```sh
q10viking@LAPTOP-PJLAUUSP:~/software/kafka_2.12-2.5.0/kafka-logs$ ls
__consumer_offsets-0   __consumer_offsets-34
__consumer_offsets-1   __consumer_offsets-35
__consumer_offsets-10  __consumer_offsets-36
__consumer_offsets-11  __consumer_offsets-37
__consumer_offsets-12  __consumer_offsets-38
__consumer_offsets-13  __consumer_offsets-39
__consumer_offsets-14  __consumer_offsets-4
__consumer_offsets-15  __consumer_offsets-40
__consumer_offsets-16  __consumer_offsets-41
__consumer_offsets-17  __consumer_offsets-42
__consumer_offsets-18  __consumer_offsets-43
__consumer_offsets-19  __consumer_offsets-44
__consumer_offsets-2   __consumer_offsets-45
__consumer_offsets-20  __consumer_offsets-46
__consumer_offsets-21  __consumer_offsets-47
__consumer_offsets-22  __consumer_offsets-48
__consumer_offsets-23  __consumer_offsets-49
__consumer_offsets-24  __consumer_offsets-5
__consumer_offsets-25  __consumer_offsets-6
__consumer_offsets-26  __consumer_offsets-7
__consumer_offsets-27  __consumer_offsets-8
__consumer_offsets-28  __consumer_offsets-9
__consumer_offsets-29  cleaner-offset-checkpoint
__consumer_offsets-3   log-start-offset-checkpoint
__consumer_offsets-30  meta.properties
__consumer_offsets-31  recovery-point-offset-checkpoint
__consumer_offsets-32  replication-offset-checkpoint
__consumer_offsets-33  test-0
```



### **Topic，Partition和Broker**

一个topic，代表逻辑上的一个业务数据集，订单相关操作消息放入订单topic，用户相关操作消息放入用户topic，对于大型网站来说，后端数据都是海量的，订单消息很可能是非常巨量的，比如有几百个G甚至达到TB级别，如果把这么多数据都放在一台机器上可定会有容量限制问题，那么就可以在topic内部划分多个partition来分片存储数据，不同的partition可以位于不同的机器上，每台机器上都运行一个Kafka的进程Broker。

**为什么要对Topic下数据进行分区存储？**

1. commit log文件会受到所在机器的文件系统大小的限制，分区之后可以将不同的分区放在不同的机器上，相当于对数据做了**分布式存储**，理论上一个topic可以处理任意数量的数据。

2. 为了**提高并行度**。



## 集群

![https://note.youdao.com/yws/public/resource/b0357bdb4821ed2e35ecdbdacd65aa06/xmlnote/EA60D4B78E4E4791B30A5B8507EBC132/122860](/images/kafka/122860.png)



## **Producers**

生产者将消息发送到topic中去，同时负责选择将message发送到topic的哪一个partition中。通过round-robin做简单的负载均衡。也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多。



## **Consumers**

传统的消息传递模式有2种：队列( queue) 和（publish-subscribe）

- queue模式：多个consumer从服务器中读取数据，消息只会到达一个consumer。
- publish-subscribe模式：消息会被广播给所有的consumer。

Kafka基于这2种模式提供了一种consumer的抽象概念：consumer group。

- queue模式：所有的consumer都位于同一个consumer group 下。
- publish-subscribe模式：所有的consumer都有着自己唯一的consumer group。

![https://note.youdao.com/yws/public/resource/b0357bdb4821ed2e35ecdbdacd65aa06/xmlnote/B579E116B1F047F6A6A563255D361013/122857](/images/kafka/122857.png)

由2个broker组成的kafka集群，某个主题总共有4个partition(P0-P3)，分别位于不同的broker上。这个集群由2个Consumer Group消费， A有2个consumer instances ，B有4个。

通常一个topic会有几个consumer group，每个consumer group都是一个逻辑上的订阅者（ logical subscriber ）。每个consumer group由多个consumer instance组成，从而达到可扩展和容灾的功能。





## **消费顺序**

一个partition同一个时刻在一个consumer group中只能有一个consumer instance在消费，从而保证消费顺序。

**consumer group中的consumer instance的数量不能比一个Topic中的partition的数量多，否则，多出来的consumer消费不到消息。**

Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性。

如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer group中的consumer instance数量也设置为1，但是这样会影响性能，所以kafka的顺序消费很少用。